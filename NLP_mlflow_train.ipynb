{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Kaggle model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/NLP/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/home/ubuntu/anaconda3/envs/NLP/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence, defaultdict\n",
      "/home/ubuntu/anaconda3/envs/NLP/lib/python3.7/site-packages/nltk/lm/vocabulary.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Counter, Iterable\n",
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#breakpoint()\n",
    "from tweets_emergency import *\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading for pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up non-default parameters\n",
    "\n",
    "try:\n",
    "    params['threshold'] = float(sys.argv[1])\n",
    "    params['lr'] = float(sys.argv[2])\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "params['model'] = sys.argv[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_CSV(train_src)\n",
    "data_size = len(data.index)\n",
    "texts = list(data['text'])\n",
    "lemmatized_texts = process_textlist(texts,\n",
    "                                    lemmatize = params['lemmatize'], \n",
    "                                    remove_stop = params['remove_stop'],\n",
    "                                    remove_nonalpha = params['remove_nonalpha'])\n",
    "masterset = create_masterset(lemmatized_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Featurization - simple one-hot encoded baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = create_vocabulary(masterset)\n",
    "mat = create_trainmat(lemmatized_texts, vocab)\n",
    "labels = np.asarray(list(data['target']), dtype = np.float32)\n",
    "#np.savetxt(\"data/mat.csv\", mat, delimiter = \",\")\n",
    "#np.savetxt(\"data/labels.csv\", labels, delimiter = \",\")\n",
    "\n",
    "tweets_dataset = tweetDataset(mat, labels)\n",
    "indices = list(range(data_size))\n",
    "split = int(data_size * (1 - params['split']))\n",
    "train_index, val_index = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_index)\n",
    "val_sampler = SubsetRandomSampler(val_index)\n",
    "\n",
    "tweets_gen_train = torch.utils.data.DataLoader(tweets_dataset, \n",
    "                                               batch_size = params['batch'], \n",
    "                                               sampler = train_sampler)\n",
    "\n",
    "tweets_gen_val = torch.utils.data.DataLoader(tweets_dataset, \n",
    "                                             batch_size = params['batch'], \n",
    "                                             sampler = val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if (params['model'] ==  'neural'):\n",
    "        model = neural(len(vocab))\n",
    "    else:\n",
    "        model = logReg(len(vocab))\n",
    "        \n",
    "    conf_matrix = confusionMatrix(params['threshold'])\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = params['lr'])\n",
    "    losses = []\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        for epoch in range(params['epochs']): # full passes over the data\n",
    "            for data in tweets_gen_train:  # `data` is a batch of data\n",
    "                X, y = data  # X is the batch of features, y is the batch of targets.\n",
    "                model.zero_grad()  # sets gradients to 0 bairefore loss calc. You will do this likely every step.\n",
    "                output = model.forward(X.float())  # forward pass\n",
    "                loss = loss_function(output, y)  # calc and grab the loss value\n",
    "                loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "                optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "            for data in tweets_gen_val:\n",
    "                X, y = data\n",
    "                model.eval()\n",
    "                output_hat = model.forward(X.float())\n",
    "                loss_hat = loss_function(output_hat, y)\n",
    "                conf_matrix.update(y, output_hat)\n",
    "            #print(\"loss in validation set is: \" + str(loss_hat.item()))  # print loss. We hope loss (a measure of wrong-ness) declines!\n",
    "            losses.append(loss_hat.item())\n",
    "            conf_matrix.calc_metrics()\n",
    "            mlflow.log_param(\"epochs\", params['epochs'])\n",
    "            mlflow.log_param(\"model\", params['model'])\n",
    "            mlflow.log_param(\"learning rate\", params['lr'])\n",
    "            mlflow.log_param(\"batch size\", params['batch'])\n",
    "            mlflow.log_param(\"classification threshold\", params['threshold'])\n",
    "            mlflow.log_param(\"lemmatize\", params['lemmatize'])\n",
    "            mlflow.log_param(\"remove_stop\", params['remove_stop'])\n",
    "            mlflow.log_param(\"remove_nonalpha\", params['remove_nonalpha'])\n",
    "            mlflow.log_metric('accuracy', conf_matrix.accuracy, step=epoch)\n",
    "            mlflow.log_metric('precision', conf_matrix.precision, step=epoch)\n",
    "            mlflow.log_metric('recall', conf_matrix.recall, step=epoch)\n",
    "            mlflow.log_metric('f1', conf_matrix.f1, step=epoch)\n",
    "    \n",
    "        #conf_matrix.output()\n",
    "        #losses_np = np.asarray(losses, dtype = np.float32)\n",
    "        #np.savetxt(\"data/losses.csv\", losses_np, delimiter = \",\")\n",
    "        #mlflow.log_artifact(\"home/ubuntu/tweets_emergency/data\")\n",
    "        mlflow.pytorch.log_model(model, params['model'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for i in tweets_gen_train:\n",
    "    print(i[0][1])\n",
    "    print(type(i[0][1]))\n",
    "    test_np = pd.DataFrame((i[0][1:5]).float())\n",
    "    test_np = test_np.astype(float)\n",
    "    #print(len(i[0][1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np\n",
    "test_np.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.469169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.942715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.957329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.142363\n",
       "1  0.469169\n",
       "2  0.942715\n",
       "3  0.957329"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NLP] *",
   "language": "python",
   "name": "conda-env-NLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
